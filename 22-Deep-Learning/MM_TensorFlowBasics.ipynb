{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow basic: Raw TF and Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-e1e08dd7804e>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_DATA/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_DATA/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_DATA/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_DATA/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22eb3240>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x230077f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[1].reshape(28,28),cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26143908>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUEAAAD8CAYAAADpLRYuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1hyCZpY1h6CZZe3/AcarA9roazK0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2583b240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[1].reshape(784,1),aspect=0.001) # vector reshaping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=([None,784])) #filled in at a later stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mutable variables that will be available for to the optimizer\n",
    "W=tf.Variable(tf.zeros([784,10]))\n",
    "b=tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y= tf.matmul(x,W)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32,shape=[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true,logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9105\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(1000):\n",
    "        batch_x,batch_y = mnist.train.next_batch(100)\n",
    "        sess.run(train,feed_dict={x:batch_x,y_true:batch_y})\n",
    "    \n",
    "    matches = tf.equal(tf.argmax(y,1),tf.argmax(y_true,1)) # the 1 is an axis\n",
    "    \n",
    "    acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "    \n",
    "    print(sess.run(acc,feed_dict={x:mnist.test.images, y_true:mnist.test.labels}))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.columns =[re.sub(\"[\\s\\()]\",\"_\",x) for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length__cm_', 'sepal_width__cm_', 'petal_length__cm_',\n",
       "       'petal_width__cm_', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target']=df['target'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length__cm_</th>\n",
       "      <th>sepal_width__cm_</th>\n",
       "      <th>petal_length__cm_</th>\n",
       "      <th>petal_width__cm_</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length__cm_  sepal_width__cm_  petal_length__cm_  petal_width__cm_  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "5                  5.4               3.9                1.7               0.4   \n",
       "6                  4.6               3.4                1.4               0.3   \n",
       "7                  5.0               3.4                1.5               0.2   \n",
       "8                  4.4               2.9                1.4               0.2   \n",
       "9                  4.9               3.1                1.5               0.1   \n",
       "10                 5.4               3.7                1.5               0.2   \n",
       "11                 4.8               3.4                1.6               0.2   \n",
       "12                 4.8               3.0                1.4               0.1   \n",
       "13                 4.3               3.0                1.1               0.1   \n",
       "14                 5.8               4.0                1.2               0.2   \n",
       "15                 5.7               4.4                1.5               0.4   \n",
       "16                 5.4               3.9                1.3               0.4   \n",
       "17                 5.1               3.5                1.4               0.3   \n",
       "18                 5.7               3.8                1.7               0.3   \n",
       "19                 5.1               3.8                1.5               0.3   \n",
       "20                 5.4               3.4                1.7               0.2   \n",
       "21                 5.1               3.7                1.5               0.4   \n",
       "22                 4.6               3.6                1.0               0.2   \n",
       "23                 5.1               3.3                1.7               0.5   \n",
       "24                 4.8               3.4                1.9               0.2   \n",
       "25                 5.0               3.0                1.6               0.2   \n",
       "26                 5.0               3.4                1.6               0.4   \n",
       "27                 5.2               3.5                1.5               0.2   \n",
       "28                 5.2               3.4                1.4               0.2   \n",
       "29                 4.7               3.2                1.6               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "120                6.9               3.2                5.7               2.3   \n",
       "121                5.6               2.8                4.9               2.0   \n",
       "122                7.7               2.8                6.7               2.0   \n",
       "123                6.3               2.7                4.9               1.8   \n",
       "124                6.7               3.3                5.7               2.1   \n",
       "125                7.2               3.2                6.0               1.8   \n",
       "126                6.2               2.8                4.8               1.8   \n",
       "127                6.1               3.0                4.9               1.8   \n",
       "128                6.4               2.8                5.6               2.1   \n",
       "129                7.2               3.0                5.8               1.6   \n",
       "130                7.4               2.8                6.1               1.9   \n",
       "131                7.9               3.8                6.4               2.0   \n",
       "132                6.4               2.8                5.6               2.2   \n",
       "133                6.3               2.8                5.1               1.5   \n",
       "134                6.1               2.6                5.6               1.4   \n",
       "135                7.7               3.0                6.1               2.3   \n",
       "136                6.3               3.4                5.6               2.4   \n",
       "137                6.4               3.1                5.5               1.8   \n",
       "138                6.0               3.0                4.8               1.8   \n",
       "139                6.9               3.1                5.4               2.1   \n",
       "140                6.7               3.1                5.6               2.4   \n",
       "141                6.9               3.1                5.1               2.3   \n",
       "142                5.8               2.7                5.1               1.9   \n",
       "143                6.8               3.2                5.9               2.3   \n",
       "144                6.7               3.3                5.7               2.5   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "5         0  \n",
       "6         0  \n",
       "7         0  \n",
       "8         0  \n",
       "9         0  \n",
       "10        0  \n",
       "11        0  \n",
       "12        0  \n",
       "13        0  \n",
       "14        0  \n",
       "15        0  \n",
       "16        0  \n",
       "17        0  \n",
       "18        0  \n",
       "19        0  \n",
       "20        0  \n",
       "21        0  \n",
       "22        0  \n",
       "23        0  \n",
       "24        0  \n",
       "25        0  \n",
       "26        0  \n",
       "27        0  \n",
       "28        0  \n",
       "29        0  \n",
       "..      ...  \n",
       "120       2  \n",
       "121       2  \n",
       "122       2  \n",
       "123       2  \n",
       "124       2  \n",
       "125       2  \n",
       "126       2  \n",
       "127       2  \n",
       "128       2  \n",
       "129       2  \n",
       "130       2  \n",
       "131       2  \n",
       "132       2  \n",
       "133       2  \n",
       "134       2  \n",
       "135       2  \n",
       "136       2  \n",
       "137       2  \n",
       "138       2  \n",
       "139       2  \n",
       "140       2  \n",
       "141       2  \n",
       "142       2  \n",
       "143       2  \n",
       "144       2  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y= df['target']\n",
    "X=df.drop('target',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length__cm_</th>\n",
       "      <th>sepal_width__cm_</th>\n",
       "      <th>petal_length__cm_</th>\n",
       "      <th>petal_width__cm_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.00000</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.882857</td>\n",
       "      <td>3.031429</td>\n",
       "      <td>3.88381</td>\n",
       "      <td>1.250476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.833950</td>\n",
       "      <td>0.407222</td>\n",
       "      <td>1.74511</td>\n",
       "      <td>0.769756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.60000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.50000</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.500000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.10000</td>\n",
       "      <td>1.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.700000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>6.90000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length__cm_  sepal_width__cm_  petal_length__cm_  \\\n",
       "count         105.000000        105.000000          105.00000   \n",
       "mean            5.882857          3.031429            3.88381   \n",
       "std             0.833950          0.407222            1.74511   \n",
       "min             4.400000          2.000000            1.00000   \n",
       "25%             5.100000          2.800000            1.60000   \n",
       "50%             5.800000          3.000000            4.50000   \n",
       "75%             6.500000          3.300000            5.10000   \n",
       "max             7.700000          4.200000            6.90000   \n",
       "\n",
       "       petal_width__cm_  \n",
       "count        105.000000  \n",
       "mean           1.250476  \n",
       "std            0.769756  \n",
       "min            0.100000  \n",
       "25%            0.300000  \n",
       "50%            1.400000  \n",
       "75%            1.900000  \n",
       "max            2.500000  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get the features in a format that can be used as input to algorithms. This is similar to the MlLib VectorAssembler class\n",
    "## that is used as input to estimators\n",
    "feats = []\n",
    "for col in X.columns:\n",
    "    feats.append(tf.feature_column.numeric_column(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='sepal_length__cm_', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='sepal_width__cm_', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='petal_length__cm_', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='petal_width__cm_', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note that the inputs is more than putting it into a structure. It also performs the batching. This is not the case with MLLib \n",
    "## VectorAssembler.\n",
    "tf_input=tf.estimator.inputs.pandas_input_fn(x=X_train, y=y_train, batch_size=10,num_epochs=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## create the estimator instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\mattma\\AppData\\Local\\Temp\\tmpha_fj0g8\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\mattma\\\\AppData\\\\Local\\\\Temp\\\\tmpha_fj0g8', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000000002D957198>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# The DNNClassifier uses the RELU by default\n",
    "classifier= tf.estimator.DNNClassifier(hidden_units=[10,20,10],n_classes=3,feature_columns=feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\mattma\\AppData\\Local\\Temp\\tmpha_fj0g8\\model.ckpt.\n",
      "INFO:tensorflow:loss = 12.701054, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 50 into C:\\Users\\mattma\\AppData\\Local\\Temp\\tmpha_fj0g8\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.7253693.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x2d957588>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Again, invoking train on the model trains it.\n",
    "classifier.train(input_fn=tf_input,steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_fn=tf.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\mattma\\AppData\\Local\\Temp\\tmpha_fj0g8\\model.ckpt-50\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(classifier.predict(input_fn=pred_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]['class_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out just the the predicted classes\n",
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  0  0]\n",
      " [ 0 13  2]\n",
      " [ 0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,final_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      0.87      0.93        15\n",
      "           2       0.86      1.00      0.92        12\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.96      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,final_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
